{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "n6g1CJDpQ3p-",
        "aL2qNGBCOJvj",
        "WoEzSrzfOU_L",
        "Xh5oK1gFOcux",
        "QTGAj-0toAjG",
        "eyMrbAY5Knzn",
        "afq9C1gZKu1a",
        "Oa3yaUoM_d2F",
        "rpyR6woBL30b"
      ],
      "authorship_tag": "ABX9TyOkJezMpj9m9++hIQzzdXRD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSShail/Machine-Learning/blob/main/credit_card_fraud_detection_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "n6g1CJDpQ3p-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJxcGO_c_rf0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,accuracy_score,classification_report\n",
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Acquisition"
      ],
      "metadata": {
        "id": "aL2qNGBCOJvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Reading the CSV file into a dataframe*"
      ],
      "metadata": {
        "id": "Vhvh0UMPcHhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credit_df=pd.read_csv('creditcard.csv')"
      ],
      "metadata": {
        "id": "_rPYg9uRA61G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Dropping the Na rows and columns *"
      ],
      "metadata": {
        "id": "bVNiir_UcN-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Preprocessing\n",
        "\n",
        "**we will check if the data needs transformation**\n",
        "*  label encoding\n",
        "*  ordinal encoding\n",
        "*  column transformation\n",
        "*  function transformer\n",
        "*  power transformer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WoEzSrzfOU_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credit_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "y2N_OZE4FGB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Visualization"
      ],
      "metadata": {
        "id": "Xh5oK1gFOcux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting heatmap to check the relationships in the dataset**"
      ],
      "metadata": {
        "id": "kG9pEdTJOiUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corelation_matrix=credit_df.corr()\n",
        "plt.figure(figsize=(14,8))\n",
        "sns.heatmap(corelation_matrix,annot=False,cmap='coolwarm',linewidths=1.5)\n",
        "plt.title('Corelation heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UwXlfKRKOh6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*training the data into train and test data*"
      ],
      "metadata": {
        "id": "8jCZKCRvbDs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=credit_df.drop(columns=['Class'])\n",
        "y=credit_df['Class']\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n"
      ],
      "metadata": {
        "id": "sLxfhp3eA5WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Looking at the data structure(column wise)*\n",
        "\n",
        "*we will use QQ plot for looking at the data distribution*\n"
      ],
      "metadata": {
        "id": "QQb2uPpjPuuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X_train.columns:\n",
        "    fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(14,6))\n",
        "    sns.distplot(X_train[col],ax=ax[0])\n",
        "    ax[0].set_title(f'KDE Plot for {col}')\n",
        "\n",
        "    qqplot(X_train[col],line='s',ax=ax[1])\n",
        "    ax[1].set_title(f'QQ Plot for {col}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pzG2SZnZP7SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax Regression-Logistic Regression"
      ],
      "metadata": {
        "id": "QTGAj-0toAjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We will apply softmax regression because it is a multi-class regression problem statement*"
      ],
      "metadata": {
        "id": "MzUhP1bir5GZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we need to scale the input features before fitting into the model"
      ],
      "metadata": {
        "id": "hjc2A3WMtbnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar=StandardScaler()\n",
        "\n",
        "X_train_scaled=scalar.fit_transform(X_train)\n",
        "X_test_scaled=scalar.transform(X_test)"
      ],
      "metadata": {
        "id": "l4eVKPxRtj3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The hyper-parameter used in the softmax regression is*\n",
        "1.   max_iter\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "etld-8iSIN1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#using multi-class as multinomial the LogisticRegression becomes SOFTMAX REGRESSION\n",
        "LoR=LogisticRegression(multi_class='multinomial',max_iter=1000)\n",
        "LoR.fit(X_train_scaled,y_train)\n",
        "y_pred_lor=LoR.predict(X_test_scaled)\n",
        "print(accuracy_score(y_pred_lor,y_test))\n",
        "print(classification_report(y_pred_lor,y_test))"
      ],
      "metadata": {
        "id": "6onrHKhBoRU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   The recall is 77\n",
        "*   The precision for fraud is 69 precent\n",
        "\n"
      ],
      "metadata": {
        "id": "XMj3ktW2ueFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "eyMrbAY5Knzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parmas={\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [5, 10, 15, 20, 25],\n",
        "    'min_samples_leaf': [1, 5],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}"
      ],
      "metadata": {
        "id": "dO2vuPztAll0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Appying GridSearchCV on DecisionTreeClassifier**"
      ],
      "metadata": {
        "id": "NAE_6crhbK_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_clf=DecisionTreeClassifier()\n",
        "\n",
        "grid_search=GridSearchCV(estimator=dt_clf, param_grid=parmas, cv=5)\n",
        "grid_search.fit(X_train,y_train)\n",
        "\n",
        "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "15ERz4XxBOBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*we will use the output of GridSearchCV and Hypertune the decision tree parameters*"
      ],
      "metadata": {
        "id": "IyLWMO2abfhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Hyperparamters used in the decision tree are\n",
        "  1.   criterion\n",
        "  2.   max_depth\n",
        "  3.   min_samples_leaf\n",
        "  4.   min_samples_split"
      ],
      "metadata": {
        "id": "T41Dz7RlIGEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#decison tree with hyperparameter tuining\n",
        "decision_tree_clf=DecisionTreeClassifier(criterion='gini')\n",
        "decision_tree_clf =decision_tree_clf.fit(X_train,y_train)\n",
        "y_pred_dt=decision_tree_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "d8VoKP60Bbg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Calculating the accuracy and classification report*"
      ],
      "metadata": {
        "id": "KysVyFmsbqLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "print(classification_report(y_test,y_pred_dt))\n",
        "\n",
        "print(accuracy_score(y_pred_dt,y_test))"
      ],
      "metadata": {
        "id": "WVlqp-kkDX9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   F1 score is 1- that means model is ideal\n",
        "*   The accuracy is also 100 percent\n",
        "\n"
      ],
      "metadata": {
        "id": "W2rfq9XIF7Ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The biggest concern is the data - the dataset is imbalanced so we need to work on imbalanced dataset*"
      ],
      "metadata": {
        "id": "H0ydmELL_Rz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest - Bagging Ensemble"
      ],
      "metadata": {
        "id": "afq9C1gZKu1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Appying GridSearchCV on RandomForest*"
      ],
      "metadata": {
        "id": "iQfanG4Tb1C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_parmas={\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'n_estimators':[5,10,15,20],\n",
        "    'max_depth': [5, 10, 15, 20, 25],\n",
        "    'min_samples_leaf': [1, 5],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}"
      ],
      "metadata": {
        "id": "K2gHOK3hGjdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf1=RandomForestClassifier()\n",
        "grid_search=GridSearchCV(estimator=rf1, param_grid=rf_parmas, cv=5)\n",
        "grid_search.fit(X_train,y_train)\n",
        "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "oZSNXTBYF1fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Hyperparameters used for the random forest is\n",
        "  1.  n_estimators\n",
        "\n",
        "*   Hyperparamters used in the decision tree of the random forest are\n",
        "  1.   criterion\n",
        "  2.   max_depth\n",
        "  3.   min_samples_leaf\n",
        "  4.   min_samples_split\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IH9f9bKTGGnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf2=RandomForestClassifier(n_estimators=5,criterion='gini',max_depth=5,min_samples_leaf=1,min_samples_split=2)\n",
        "rf2.fit(X_train,y_train)\n",
        "y_pred=rf2.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "J8I8m8Q0L2DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiriBoURd3gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance using random Forest"
      ],
      "metadata": {
        "id": "Oa3yaUoM_d2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn"
      ],
      "metadata": {
        "id": "uw02V6XiDsYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "# Separate features and target variable\n",
        "X = credit_df.drop('Class', axis=1)\n",
        "y = credit_df['Class']\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "X.dropna(inplace=True)\n",
        "y.dropna(inplace=True)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"X_resampled: \", X_resampled)\n",
        "print(\"y_resampled: \", y_resampled)\n",
        "\n",
        "\n",
        "#For Feature importance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model to determine feature importances\n",
        "rf.fit(X_resampled, y_resampled)\n",
        "\n",
        "\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf.feature_importances_\n",
        "\n",
        "# Display feature importances in a sorted manner\n",
        "feature_importances_sorted = sorted(zip(feature_importances, X_resampled.columns), reverse=True)\n",
        "\n",
        "#print(feature_importances_sorted)\n",
        "for importance, feature in feature_importances_sorted:\n",
        "    print(f\"Feature: {feature}, Importance: {importance}\")### Feature Importance using Random Forest"
      ],
      "metadata": {
        "id": "GEWlXTjq_pqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We will select three most relevant features after appying feature importance. Those features are as given below*\n",
        "1.   V14\n",
        "2.   V10\n",
        "3.   V12\n",
        "\n",
        "We will create a dataframe(X_selected and y_selected) consisting of these above columns and perform the ML algo.\n",
        "\n"
      ],
      "metadata": {
        "id": "KBHqKrkyJ7jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_selected=X_resampled[['V14','V12','V10']]\n",
        "y_selected=y_resampled"
      ],
      "metadata": {
        "id": "HYzYn8LJK2-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*splitting the data into training set and test set*"
      ],
      "metadata": {
        "id": "eZcuYvusMESs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X_selected,y_selected,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "T8TROYn0MDyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression after feature importance"
      ],
      "metadata": {
        "id": "rpyR6woBL30b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar=StandardScaler()\n",
        "\n",
        "X_train_scaled=scalar.fit_transform(X_train)\n",
        "X_test_scaled=scalar.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#using multi-class as multinomial the LogisticRegression becomes SOFTMAX REGRESSION\n",
        "LoR=LogisticRegression(multi_class='multinomial',max_iter=1000)\n",
        "LoR.fit(X_train_scaled,y_train)\n",
        "y_pred_lor=LoR.predict(X_test_scaled)\n",
        "print(accuracy_score(y_pred_lor,y_test))\n",
        "print(classification_report(y_pred_lor,y_test))"
      ],
      "metadata": {
        "id": "GDLwOO8VLJuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yv1a1dAkM5ui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}